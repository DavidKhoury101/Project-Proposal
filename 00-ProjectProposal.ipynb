{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Project Proposal\n",
    "\n",
    "## Authors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cassidy Burns: Conceptualization, Background research, Project administration\n",
    "- Mason Oelschlager: Conceptualization, Project administration\n",
    "- Vu Luong: Conceptualization, Project administration\n",
    "- David Khoury: Conceptualization, Project administration\n",
    "- Jorell Jusay: Conceptualization, Project administration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do player base and revenue decline metrics affect the probability of server shutdown in online multiplayer games?\n",
    "\n",
    "Note: \"Dead\" being the point at which the concurrent player bases can no longer financial sustain the cost of maintainig online, multiplayer video game services requiring the use of servers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online games depend on sustained player engagement to justify whether the ongoing costs of server infrastructure, moderation and updates are worth the price. While publishers regularly shut down games due to a decline in engagement or financial loss, there is no publicly standardized, data-driven threshold for when a game is necessarily considered “dead.” Although decisions are normally framed as business or legal necessities, the supposed “breaking point” for shut down remains vague. This lack of transparency for the audience can cause uncertainty on whether to continue investing their time, money, and resources into an unknown future.\n",
    "\n",
    "Prior studies mainly focus on player count trajectories as the main signal of a game’s health. Platforms allow for people to track concurrent player counts over time and can be used to identify sharp falloffs following launch or specific updates. Through the analysis of failed live-service games (Multiversus, whatever we think of), there is a recurring pattern with an early peak followed by a rapid decline. Although there is reason to believe player count alone can capture a game’s potential life, it does not account for whether the remaining players are continuing to engage with the material. \n",
    "\n",
    "Related work has approached this issue by examining player engagement and churn rather than explicitly defining when a game should be shut down. In Improved Retention Analysis in Freemium Role-Playing Games by Jointly Modelling Players’ Motivation, Progression and Churn, the authors analyze how player motivation, in-game progression, and achievement activity relate to long-term retention. Their findings suggest that declining progression and reduced engagement are strong indicators of when players are likely to stop playing altogether, even if the game still maintains an active user base.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) Similarly, A Data Imputation Strategy to Enhance Online Game Churn Prediction, Considering Non-Login Periods focuses on how extended periods of inactivity can signal permanent disengagement rather than temporary absence. By improving how non-login behavior is modeled, the study shows that sustained inactivity is a reliable predictor of churn.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) While neither study proposes a clear threshold for declaring a game “dead,” both highlight that long-term declines in engagement and progression provide measurable signals of a game’s deterioration beyond what player count alone can capture.\n",
    "\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Lee, JaeHong, et al. “A Data Imputation Strategy to Enhance Online Game Churn Prediction, Considering Non-Login Periods.” MDPI, Multidisciplinary Digital Publishing Institute, 23 June 2025, www.mdpi.com/2306-5729/10/7/96.\n",
    "\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Karmakar, Bikram, et al. “Improved retention analysis in freemium role-playing games by jointly modelling players’ motivation, progression and churn.” Journal of the Royal Statistical Society Series A: Statistics in Society, vol. 185, no. 1, 11 Aug. 2021, pp. 102–133, https://doi.org/10.1111/rssa.12730.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relating to our question, online games can be considered “dead” when player count, achievement completion rate, and reviews all show negative averages over time in relation to peak engagement. Our hypothesis is that games officially shut down by publishers will exhibit similar patterns of declining player count, stagnating achievement progression, and worsening reviews. This will allow us to provide a measurable threshold that can be used to evaluate current online games and their potential. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \n",
    "The ideal dataset would combine data on player activity, engagement, general sentiment, and shutdown outcomes across many online games. The observation would ideally focus on a fixed time interval, like every week or month, to see how trajectories differ between games that failed versus games that remain active. The dataset/s would include multiple categories of variables, a prominent one being player activity metrics. This would focus on the number of average concurrent players, the number of players during the games’ peak, and monthly active users over time. This information would be critical in determining likely necessary metrics such as the percentage change in player count relative to the historical peak, and player count volatility to see if player count is predictable or not. Another variable would be engagement metrics such as the average playtime per user, the number of achievements and progression milestones being completed, login frequency, and the proportion of returning players vs. new players. Also, churn is a good indicator of seeing the percentage of players inactive and the monthly churn rate. Lastly, sentiment variables, including user reviews and control variables like the monetization model, platform, release data, and major updates, are good indicators for why a game is performing well or not. \n",
    "\n",
    "Observations would ideally span from each game’s launch until the present or its shutdown, and the dataset would ideally include at least 100 online games, and data being stored in a standardized longitudinal format with CSV files, as this would allow for direct comparison of the variables across games and we will be able to identify reasons for a games shutdown or continued success. We would analyze historical data from both games that have already been shut down, those that are near a shutting down point, and that are healthy, to determine at what point the upkeep of servers is justified.\n",
    "\n",
    "In terms of ideal versus real data sets. The following are some tangible data sets that we have been able to uncover, though some specific variables will require more sophisticated gathering or scraping. \n",
    "So, realistically, some variables, such as monetization models, may have to be supplemented with a reasonable estimate given industry standards because that information is not publicly available. However, there are real data sets available for historical data for player counts (particularly on an average user basis per month), user review data, and game update data. There are some limitations with this, such as steam API’s only allowing for so much use at a time, but it should be manageable on a reasonable basis.\n",
    "\n",
    "2. \n",
    "https://www.kaggle.com/datasets/lunthu/steam-monthly-average-players\n",
    "\n",
    "This url above show where this real dataset that we found come from, it comes from Kaggle where the data was scrap from steamcharts.com that shows the monthly average player counts of over 6000 games on Steam. And since it is publicly available on Kaggle, we won't havee to ask for permission or fill out any form to use this dataset. The important variable(s) that we might use from this dataset to help us answer our research question is avg_players(average player count), gain_percent(the percent differences in player counts compare to previous months) and peak_players(highest player count of that month), and by using these 3 variables, we can see how a game is performing monthly which can help us see if a game is doing well or if it is slowly dying over time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics \n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "> We have considered this issue and since we are using publicly available datasets, there won't be any human subject and they are already given informed consent due to the dataset being public\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "> There are possible biases within the datasets we plan to use. Since the statistics that are publicly accessible come from platforms like Steam, console players or private profile players may not be represented within the data. In addition, review data can be skewed because players who leave reviews often have very strong positive or negative opinions, which may not fully represent the “average” player. To reduce these issues we will clearly acknowledge these limitations when presenting our analysis/results.\n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "> we have considered this and will only use data that is publicly available or already anonymized so no personal data is included. We will ensure that the data we collect or analyze follows platform terms of service and standard ethical practices for data use.\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "> Yes we have considered this and we think that we can enable testing downstream results for bias outcomes by periodically test if our model is being biased based on things like if a game is made by a AAA companies or an indie companies, things like that to ensure that our model/results apply fairly across all game when analyzing if a game is dead or not.\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    "> Since we are using publicly available data and we will make sure that the data will be anonymized, there won't be much concern when its come to protecting and securing data since there won't be sensitive data that can do harm to our subjects that the dataset come from.\n",
    "\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "\n",
    "> Since we are thinking of using public datasets, we have considered this and we think that if an individual does request us to removed their information from the datset that we are using for our research, then we will manually delete them from the dataset we are using.\n",
    "\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    ">Yes, we are thinking of deleting data 30 days after it is no longer needed.\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "> Yes, we have considered addressing blindspot in our analysis by engaging with relevant stakeholders such as the communities of these games to see whether the game that we deemed as dead is still actually very much alive and active by selecting a number of communities of game we deemed as dead or alive, and by engaging with those communities, we can see if our analysis was correct or is there any blindspot within our analysis. And if there is blindspot, we will try out best to revise our analysis to reflect that as much as possible in our final report/analysis/result.\n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "> Yes, as mentions before, we believed that there is possible biases such as from review being skewed since only really positive or negative opinion will leave reviews, so we plan to mitigate this by taking the average of these review to reflect the more average player base opinion on a game. We also believed another possible bias is with our player count dataset if we are to use it, is that when a game goes on sale on steam or when it win a games award, there will be a big spike in average player count in the month, so we plan to mitigate this by taking these things into account when we do our analysis.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "> We have considered this and believed that we can ensured that our visualization/summary statistics/report honestly represent our underlying dataset by making sure we don't manipulated our data to make our visualization fit what we want and instead let it be and only make our visualization easier to understand for the reader. The same apply for our summary statistics and report.\n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    "> We have considered this and to ensured this, we will only use anonymized and public data as well as not display any data with PII unless absolutely necessary for the analysis which we think is not necessary at all, and that the anonymized data is all we will need for our analysis hence we can minimized any privacy issues in our analysis.\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "> We have considered this and we plan to make sure that our analysis is well documented and reproducible in the future by doing things like keeping our raw dataset as csv files to keep them clean and untouch and only do our analysis with the data with a copy of the raw dataset we use. We will also make sure to script all of our steps like data cleaning, modeling, etc. And since we are using github that will also give us version control which will make it more well documented.\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    "> Yes, we have considered this because since we using things like average player count or positive/negative review, our variables shouldn't be unfairly discriminatory, since if anything there could be bias in them, but as we have said earlier that we will take steps to mitigate these biases, we think we will be good.\n",
    "\n",
    " - [] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    "\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    "> Yes, we have considered this, and to ensure that no bias or unintended issue will come from this, we won't be optimizing our defeined metrics and will have many additional metrics when considering answering our question to keep it as unbias and fair as possible.\n",
    "\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    "\n",
    "> Yes, we have considered this and we think and we can keep it understandable by making sure that in our final report, we can explain why exactly our model made certain decision if a justification is needed, and to make sure to note in our report why our models make the decisions it did to make it easier to understand for our readers.\n",
    "\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "> Yes, we have considered this and we will ensured that we will communicate any shortcomings/limitations/biases of our mode to the relevant stakeholders in a way they can understand in our final report. Such as noting our biases that we might come across in our dataset/model or maybe noting that labeling a game as “dead” based only on numerical trends could overlook players who still actively enjoy the game. Because of this, we will frame our results as indicators of engagement decline rather than definitive judgments about a game's value or community.\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "\n",
    "> We plan to monitor our model and its impacts after it is deployed by checking its performance, especially if the results are the same with different datasets, as well as seeing if our model results truly reflect that to the same as the communities of games that it is analyzing.\n",
    "\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "\n",
    "> Yes, we have considered this and think that our response for if users are harmed because of the results of our model, we will pull back of model and update our analysis and model with different dataset and analyzed what is causing the harm so we can update our analysis/model to prevent future harm.\n",
    "\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "\n",
    "> Yes, we think that we can just pull back the model if necessary.\n",
    "\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    "> Yes, we think that by making sure that our model is made specifically for just analysis whether a game is dead, we can minimized any unintended usage and abuse of our model. And we plan to minotor these usage once our model is deployed by keeping track of who can get access to our model and check with them on what they are using our model for."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Respond within 48 hours for a response to a message*\n",
    "* *On average, we will have 1 meeting per week online*\n",
    "* *If anyone have any opinion/contribution, don't be afraid to reach out to the groupchat*\n",
    "* *We will do so by majority vote (so like 3 out of the 5 agree) in the case of a non-responsive member and a decision has to be made.*\n",
    "* *We can do a hybrid of specialization in term of group contribution where Vu and Jorell will work on the programming, and David, Mason, and Cassidy are working with analysis and all other related tasks, but everyone will also help out with other stuff as necessary. We will use a Google spreadsheet shared with everyone to keep track of the list of tasks and progress to make sure who is doing what and how they are progressing.*\n",
    "* *We will have a different deadline calendar to make sure that everyone is doing work and if they need any help so that they can reach out to ask for help to finish the task before the actual hard deadline is due.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss/Work at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/30  |  4:30 PM | Draft project proposal  | Review proposal; refine research question and hypothesis; assign sections for individual work | \n",
    "| 2/04  |  9 PM |  Individually work on assigned part of the project proposal | Combine sections, edit for clarity and consistency; finalize and submit project proposal | \n",
    "| 2/06  | 4:30 PM  | Start looking for dataset | Discuss dataset options; decide on final dataset; begin collecting and reviewing data |\n",
    "| 2/16  | 3 PM  | Import and clean/tidy the data; Data wrangling; Finalized Checkpoint 1 | Meet to review cleaned dataset, confirm variable definitions, and finalize analysis plan; ensure all team members are aligned on modeling approach  |\n",
    "| 3/01  | 4:30 PM  | Finalize EDA; edit all EDA portions of Checkpoint 2 | Meet to review and finalize EDA for Checkpoint 2; interpret patterns, refine visualizations, and define metrics for modeling |\n",
    "| 3/12  | 12 PM  | Edit and Finalize the jupyter notebook | Discuss structure and content of final project video; assign roles for demonstration and narration; finalize materials for submission |\n",
    "| 3/17  | 4:30 PM  | Finish Video, jupyter notebook(aka the report) | Turn in Final Project & video & Group Project Surveys |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
